-   Asynchronism in System Design

    Asynchronism is a core scalability pattern used in large-scale systems to improve responsiveness and throughput by offloading slow or expensive operations from the synchronous user-facing request path. Instead of making a user wait for long processing steps, the system performs them in the background, while the user continues smoothly.

    This pattern is found in:
    - Posting tweets → fan-out happens asynchronously
    - Uploading videos → encoding happens asynchronously
    - Payment processing → settlements happen asynchronously
    - Notifications → sent asynchronously
    - Log processing, ML pipelines, analytics → all asynchronous

-   Why Asynchronism?

    Core Benefits
    - Reduces user-perceived latency  
        Expensive operations move to background workers, making UI instantly responsive.
    - Improves system throughput  
        Workers can scale horizontally based on load.
    - Smoothens load spikes  
        Queues absorb bursts, preventing the system from being overwhelmed.
    - Supports periodic/offline work  
        Aggregations, indexing, caching, analytics can happen outside request path.

-   Message Queues

    A message queue is a buffer that stores jobs until background workers process them.

    Typical Asynchronous Workflow
    ```
    Client → Application Server → Message Queue → Worker → DB/Cache/External service
    ```

    How it works:
    1. Application publishes a job (post tweet, send email, process image)  
    2. Queue stores the job reliably  
    3. Worker consumes the job and performs expensive work  
    4. Worker updates status or writes result to DB  
    5. Application notifies the user that action has been initiated (not completed)  

    Example: Twitter Post
    - User hits "Tweet"  
    - UI instantly shows the tweet (optimistic UI)  
    - Workers asynchronously push tweet to millions of followers (fan-out on write)  

    Popular Message Queues
    | System         | Description                                                                           |
    | -------------- | ------------------------------------------------------------------------------------- |
    | Redis      | Simple, very fast, but not durable; messages can be lost                          |
    | RabbitMQ   | Mature, supports AMQP, persistent queues, routing; requires node management           |
    | Amazon SQS | Fully managed, scalable, at-least-once delivery (duplicates possible), higher latency |

-   Task Queues

    A task queue is like a message queue but focuses on executing tasks and returning results.  
    It often supports:
    - Scheduling (run every X minutes/hours)
    - Retries
    - Result storage
    - Complex workflows (chains, groups)

    Example: Celery (Python)
    Celery = Task Queue + Scheduler + Worker system  
    Used for:
    - Sending emails
    - Generating PDFs
    - Image processing
    - ML preprocessing

    Architecture:
    ```
    App → Task Queue (Redis/RabbitMQ) → Task Workers → Results Backend
    ```

-   Back Pressure

    Back pressure is a mechanism to prevent the system from collapsing when queues grow too large.

    Why it’s needed
    If queues grow:
    - Memory overflows
    - Queue spills to disk
    - Workers slow down
    - Latency increases
    - System becomes unstable

    How back pressure works
    - Set max queue size
    - If queue is full, reject new requests with:
        - HTTP 503 Service Unavailable
        - Retry-After header

    Clients retry with exponential backoff, e.g.:
    ```
    1s → 2s → 4s → 8s → 16s
    ```

    This keeps the system healthy and predictable under massive load.

-   Disadvantages of Asynchronism

    While powerful, asynchronous workflows come with tradeoffs:

    1. Increased Complexity
    Queues, workers, retry logic, dead-letter queues, monitoring… introduces operational overhead.

    2. Not Suitable for Low-Latency Synchronous Operations
    For simple operations (e.g., I/O read from cache, quick DB insert), adding a queue:
    - Increases latency
    - Adds unnecessary layers

    3. Lack of Immediate Results
    The user may need to poll for status or wait.

    4. Error Handling Becomes Harder
    You must design for:
    - Retries
    - Idempotency
    - Exactly-once semantics (tricky)

    5. Potential Duplicate Processing
    Some systems (like AWS SQS) deliver messages at least once, so:
    - Workers must be idempotent
    - DB writes must handle duplicates

-   Common Patterns Using Asynchronism

    1. Write-offloading
    Expensive writes → handled by worker  
    Examples:
    - Logging
    - Video encoding
    - Metrics ingestion

    2. Read precomputation
    Precompute results so read is cheap:
    - Search index building
    - Feed generation (fan-out)
    - Analytics rollups (hourly/daily)

    3. Event-driven architecture
    Services communicate via events:
    - UserCreated
    - OrderPlaced
    - PaymentCompleted

    4. Workflows
    Long-running multistep processes:
    - Order processing pipeline
    - Fraud detection
    - ETL and ML pipelines

-   Asynchronism Architecture (Diagram)

    ```
                                    ┌──────────────┐
                                    │   Database    │
                                    └──────┬───────┘
                                        ^
                                        │
            ┌──────────┐         ┌─────────┴────────────┐
    Client →│ API Tier │→ Queue → │ Background Workers   │
            └──────────┘         └─────────┬────────────┘
                                        │
                                        v
                                    ┌──────────────┐
                                    │ Notification │
                                    └──────────────┘
    ```

-   Real Examples

    Twitter
    - Tweet shows up instantly  
    - Fan-out to followers happens asynchronously  

    Instagram
    - Post uploaded instantly  
    - Image/video transcoding async  
    - Content moderation async  

    Amazon
    - Order placed instantly  
    - Payment settlement, inventory updates happen async  

    YouTube
    - Upload video instantly  
    - Transcoding async → multiple resolutions  

-   When to Use Asynchronism?

    Use asynchronous workflows when:
    - Operation is slow or expensive (encoding, analytics)
    - Operation can be eventual (notifications)
    - Operation must scale massively (fan-out)
    - Operation can fail & retry safely
    - You want to smooth traffic spikes

    Avoid them for:
    - Auth flows
    - Small DB reads
    - Realtime interactions (games, chat → synchronous messaging)

-   Interview Summary (Short Version)

    If asked in system-design:
    - “We use message queues to move expensive work off the request path.”
    - “Queues absorb spikes and allow horizontal worker scaling.”
    - “We use back pressure to protect the system when queues overload.”
    - “We ensure idempotency because queues may deliver messages twice.”
    - “For Python we can use Celery; for high-scale, Kafka/RabbitMQ/SQS.”
    - “Async improves latency at the cost of complexity.”
